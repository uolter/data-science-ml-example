{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "We’ll use machine learning to refer to creating and using models that are learned from data.\n",
    "\n",
    "We’ll look at both **supervised models** (in which there is a set of data labeled with the correct answers to learn from), and **unsupervised models** (in which there are no such labels). \n",
    "There are various other types like semisupervised (in which only some of the data are labeled) and online (in which the model needs to continuously adjust to newly arriving data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common danger in machine learning is **overfitting**: producing a model that performs well on the data you train it on but that generalizes poorly to any new data.\n",
    "\n",
    "The other side of this is **underfitting**, producing a model that doesn’t perform well even on the training data, although typically when this happens you decide your model isn’t good enough and keep looking for a better one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def split_data(data, prob):\n",
    "    \"\"\"split data into fractions: [prob, 1-prob]\"\"\"\n",
    "    \n",
    "    results = [], []\n",
    "    \n",
    "    for row in data:\n",
    "        results[0 if random.random() < prob else 1].append(row)\n",
    "    return results\n",
    "\n",
    "# example\n",
    "\n",
    "import dateutil.parser\n",
    "import csv\n",
    "\n",
    "data = []\n",
    "\n",
    "with open(\"../data/stocks.txt\", 'r') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    for line in reader:\n",
    "        data.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['symbol', 'date', 'closing_price'],\n",
       " ['AAPL', '2015-01-23', '112.98'],\n",
       " ['AAPL', '2015-01-22', '112.4'],\n",
       " ['AAPL', '2015-01-21', '109.55'],\n",
       " ['AAPL', '2015-01-20', '108.72'],\n",
       " ['AAPL', '2015-01-16', '105.99'],\n",
       " ['AAPL', '2015-01-15', '106.82'],\n",
       " ['AAPL', '2015-01-14', '109.8'],\n",
       " ['AAPL', '2015-01-13', '110.22'],\n",
       " ['AAPL', '2015-01-12', '109.25'],\n",
       " ['AAPL', '2015-01-09', '112.01'],\n",
       " ['AAPL', '2015-01-08', '111.89'],\n",
       " ['AAPL', '2015-01-07', '107.75'],\n",
       " ['AAPL', '2015-01-06', '106.26'],\n",
       " ['AAPL', '2015-01-05', '106.25'],\n",
       " ['AAPL', '2015-01-02', '109.33'],\n",
       " ['AAPL', '2014-12-31', '110.38'],\n",
       " ['AAPL', '2014-12-30', '112.52'],\n",
       " ['AAPL', '2014-12-29', '113.91'],\n",
       " ['AAPL', '2014-12-26', '113.99']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data row  16555\n"
     ]
    }
   ],
   "source": [
    "print(\"Data row \", len(data[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in train data  11650\n",
      "Rows in test data  4905\n"
     ]
    }
   ],
   "source": [
    "test_data, train_data = split_data(data[1:], 0.30)\n",
    "\n",
    "print(\"Rows in train data \", len(train_data))\n",
    "print(\"Rows in test data \", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['AAPL', '2015-01-23', '112.98'],\n",
       " ['AAPL', '2015-01-14', '109.8'],\n",
       " ['AAPL', '2015-01-06', '106.26'],\n",
       " ['AAPL', '2015-01-02', '109.33'],\n",
       " ['AAPL', '2014-12-29', '113.91'],\n",
       " ['AAPL', '2014-12-26', '113.99'],\n",
       " ['AAPL', '2014-12-23', '112.54'],\n",
       " ['AAPL', '2014-12-22', '112.94'],\n",
       " ['AAPL', '2014-12-19', '111.78'],\n",
       " ['AAPL', '2014-12-16', '106.75']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(x,y, test_pct):\n",
    "    \n",
    "    data = zip(x, y)\n",
    "    \n",
    "    train, test = split_data(data, 1 - test_pct)\n",
    "    x_train, y_train = zip(*train)\n",
    "    x_test, y_test = zip(*test)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "x = [[row[0], row[1]] for row in data[1:]]\n",
    "y = [row[2] for row in data[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(x, y, 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row in train x and train y  11618 11618\n"
     ]
    }
   ],
   "source": [
    "print(\"Row in train x and train y \", len(train_x), len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row in test x and test y  4937 4937\n"
     ]
    }
   ],
   "source": [
    "print(\"Row in test x and test y \", len(test_x), len(test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **True Positive**: This message is spam, and we correctly predicted spam\n",
    "- **False Positive** (Type 1 error): This message is not spam, but we predicted spam\n",
    "- **False Negative** (Type 2 error): This message is spam, but we not predicted not spam\n",
    "- **True Negative**: This message is not spam, and we correctly predicted not spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5 babies out of 1000 are named Luke\n",
    "- 14 babies out of 1000 have leukemia\n",
    "\n",
    "We assume these two factors are independent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|test     |leukemia|no leukemia|total   |\n",
    "|---------|--------|-----------|--------|\n",
    "|Luke     |     70 |      4930 | 5000   |\n",
    "|not Luke |  13930 |    981070 | 995000 |\n",
    "|total    |  14000 |    986000 |1000000 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurracy  0.9811311698194716\n"
     ]
    }
   ],
   "source": [
    "def accuracy(tp, fp, fn, tn):\n",
    "    \n",
    "    correct = tp + tn\n",
    "    total = tp + fp + fn + tn\n",
    "    return correct / total\n",
    "\n",
    "print(\"Accurracy \", accuracy(70, 4930, 13939, 981070))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems like a pretty impressive number. But clearly this is not a good test, which means that we probably shouldn’t put a lot of credence in raw accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s common to look at the combination of precision and recall. \n",
    "\n",
    "- **Precision** measures how accurate our positive predictions are.\n",
    "\n",
    "- **Recall** measures what fraction of the positives our model identified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision  0.014\n"
     ]
    }
   ],
   "source": [
    "def precision(tp, fp, fn, tn):\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "print(\"Precision \", precision(70, 4930, 13930, 981070))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall  0.005\n"
     ]
    }
   ],
   "source": [
    "def recall(tp, fp, fn, tn):\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "print(\"Recall \", recall(70, 4930, 13930, 981070))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are both terrible numbers, **reflecting that this is a terrible model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score  0.00736842105263158\n"
     ]
    }
   ],
   "source": [
    "def f1_score(tp, fp, fn, tn):\n",
    "    p = precision(tp, fp, fn, tn)\n",
    "    r = recall(tp, fp, fn, tn)\n",
    "    return 2 * p * r / (p + r)\n",
    "\n",
    "print(\"F1 Score \", f1_score(70, 4930, 13930, 981070))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score reaches its best value at 1 and worst at 0. [F1 score](https://en.wikipedia.org/wiki/F1_score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
